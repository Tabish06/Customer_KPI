Software  Preannouncements
and Their Impact on
Customers' Perceptions
and Vendor Reputation

JOHNA.HOXMEIER

JOHN A. HOXMEIER is an Assistant Professor of Computer Infonnation Systems at Colo-
rado State University. He received his Ph.D. from the University of Colorado-Moulder.
Prior to joining CSU in  1995, he was Executive VP and CIO at the Fuller Brush Com-
pany, where he was actively  involved  in a major  reengineering  effort  and  corporate
acquisition. He was a founder and principal of a national software company that devel-
oped and marketed  a relational textual database product. He is an active educator and
researcher  in the areas of database quality, performance, and IS strategic planning.

ABSTRACT:  Software  preannouncements  are often  called  "vaporware" (systems  or
features announced long before a ship date). The challenge confronting software ven-
dors  and  consumers  is understanding  the balance  between  the  need  to  inform  the
market  and  the negative  consequences  of unfulfilled  promises. Based  on  signaling
theory from marketing science and research, this study looks at the perceived  impor-
tance of software preannouncement factors on customers, of unfulfilled  promises and
unreliable  software  on  a  company's  reputation,  and  whether  vendor  dependence
changes  these  perceptions.  Database  administrators  were  surveyed  on  the percep-
tions of their database software vendor. Fulfilling commitments to software  function-
ality was more strongly  correlated  with vendor reputation  than  on-time delivery  of
the software.  Customer  dependence on the vendor  was not correlated  with  percep-
tions of vendor reputation and credibility. Thus, unlike other industries, it seems that
vendors can use software delivery time preannouncements for competitive purposes
with minimal concern for the impact on customers, provided the software  ultimately
delivers the features and functionality promised and is largely free of errors.

KEY  WORDS  AND  PHRASES: corporate reputation, signaling,  software  preannounce-
ments, vaporware.

Information  technology promises  are too often of the piecrust  sort:

easily made and easily broken.

—Peter G.W. Keen (1998)

Jownal of Management Information Systems /S}matialWi,Wo\.  17,No. l.pp. 115-139.

O 2000 M,E. Sharpe. Inc.
0742-1222 / 2000 $9,50 + 0.00.


116 

JOHN  A.  HOXMEIER

SOFTWARE COMPANIES USE A MARKET SIGNALING TECHNIQUE called "product prean-
nouncing"—a  deliberate  communication  before  a firm  performs  a particular  action
[10]. Software  preannouncements  are often  called "vaporware" (systems or features
announced long before a ship date) and have existed in the software industry since the
1980s [30]. In some cases the software  product or feature  may never even appear [7,
18]. The preannouncement is usually a market signal directed at consumers, competi-
tors, investors, distributors, and the sales force.

Vaporware can have both  positive and  negative effects.  Positive effects  can  occur
when a software  company communicates delivery dates or details of planned or un-
finished  work to customers. This information  can then be used to help with  business
planning, or with  system  integration, or to refine  or improve  the  software.  Vendors
that  produce  compatible  products  need this  information  for  development  purposes.
According to Microsoft  in Judge Stanley Sporkin's denial of the proposed  1995 anti-
trust litigation consent decree, "Its [vaporware's] purpose is to engage customers and
the industry  in a useful  dialogue about products that help customers  make better de-
cisions and developers  make better products" [62, p.  15]. Negative effects  can occur
when a software company does not fulfill  its intentions after preannouncing a product
they  are "dry-testing," do not  know they can  build, or do not  have any intention  of
releasing,  or  when  they  announce  unrealistic  delivery  dates  [18,  52].  Misleading
preannouncements can diminish trust in vendors' claims and add to uncertainty [27].
Customers  may  make decisions  to hold off  buying new  software,  potentially  losing
efficiency  or impacting  their  business  plan  as a result. Competitors  can  lose  sales,
especially  if they are not the market leader. It could possibly drive smaller competi-
tors out of husiness. Also, resellers and developers of compatible or value-added  soft-
ware may lose sales at critical times.

Many  examples  of  vaporware exist  in  the software  marketplace  [14,  16,  18, 52].
Ovation Technologies, in an effort  to solicit support for a DOS-based  integrated  soft-
ware package, prepared a demonstration  they promoted  at trade shows. But the pro-
duction  software  simply didn't exist. The demo was dry-tested  in an attempt  to raise
capital. Before  the product could be released, the company went bankrupt. Visicorp,
the maker of Visicalc, the world's first spreadsheet program, announced VisiOn, which
was to be a competitor  to Windows. But  by the  time  it was to be released  in  1984,
Visicorp was out of business. Microsoft  announced Windows  1.0 in November  1983
for availability in June  1984. It was actually shipped in November  1985. Windows 95
was  originally  announced  for  availability  at  the  end  of  1994,  but  finally  made  to
market it at the end of August  1995. Microsoft  announced Quick Basic 3.0 in Novem-
ber  1986.  Critics  said  they  announced  it  in  hopes  of  hurting  sales  of  Borland's
TurboBasic, which had been announced  but not yet shipped  [62]. Judge Sporkin re-
ferred  to Microsoft  employees' efforts  to discourage  sales of a competitor's  product
by preannouncing  their own product to hold off Turbo buyers.

There is a delicate balance between the positive and negative effects  that can result
from  software  preannouncements  and  market  signaling. There  can  be  unintended
consequences  of  a  signal.  Unlike  the  time  when  enterprise  applications  could  be


SOFTWARE PREANNOUNCEMENTS. CUSTOMERS' PERCEPTIONS, VENDOR REPUTATION  117

developed using COBOL, information  systems development today is highly depen-
dent  upon  the vendors  who supply  the tools and  teehnologies. Understanding  and
interpreting market signals  is important to most, if not all, IS shops. The  challenge
confronting  software  vendors is understanding and managing preannouncements in
terms of the market impact of breaking promises and delivering poor-quality or late
software.

The research study was designed to explore several questions. What are customers'
perceptions of the relative inoportance of market signal  factors  in the software  mar-
kets, includmg on-time delivery, fiilfilled fimctionaUty promises, and software  reli-
ahility? Are the predictions of market  signal theory  valid  in software  markets?  Do
expectations of customer dependence from marketing research apply to software prod-
ucts?  Finally, what is a true market signal in the software  market? The  relationship
between  software  vendors  and  their  customers  is analyzed  using  signaling  theory
described  in marketing  research  and  marketing  science.  Specifically,  the  study  ex-
plores the preannouncement  factors  that  customers perceive  as  important,  the rela-
tionship between unfulfilled  promises and a company's reputation, and whether vendor
dependence changes these perceptions.

A Review of the Literature

THE  FOLLOWING  LITERATURE  REVIEW  FOCUSES on the two areas of concem  in this
study: vaporware  and market  signaling. Vaporware  is not an area that has been  ex-
plored in great detail within IS research. As such, most of the information  presented
has been gleaned from  practice and trade publications, where vaporware is a contro-
vei^ial topic. Market signaling has gained wide acceptance in marketing research.

Vaporware

Software  companies today face many challenges. Creating a piece of software  is un-
like the creation of any other product [50]. The complexity or size of the project can
be easily underestimated and the software  is delivered late or becomes impossible to
finish.  There  are  many  reasons  for  this  phenomenon.  As  hardware  becomes  more
powerful,  larger  and  more  complex  programs  are written  to take  advantage  of  the
additional capability. Also, as the size of a program grows, programmer  productivity
falls and the number of en-ors increases [44]. Basic software design ftaws, lack of plan-
ning, poor product management, and shoddy testing are also factors that can create prob-
lems  in  the  software  development  process  [50,  67]. Due  to  increasing  business
demands and  rapid  advances  in hardware  technology,  the development  cycles  for
software  have shortened considerably. In addition, the development cycle has become
more complicated because of the increasing number of requirements. Software  must
now be compatible with many platforms, support hundreds of devices and protocols,
and  be able to provide  complex  yet  intuitive  functions  and  features  [4]. This  com-
plexity contributes to the difficulty  of making accurate product preannouncements.


118 

JOHNA.HOXMEIER

There  are  benefits  and  costs  a company  has  to consider  before  preannouncing  a
product.  Benefits  from  product preannouncing  include  favorable  positioning  of  the
new  product,  forestalling  customer  purchases  of  rival  products,  establishing  price
levels,  signaling  the  firm's  commitment  to  new  technology,  decreasing  consumer
switching costs, educating the market, and lowering consumer learning requirements
127, 32]. Costs from  product preannouncing  include the cannibalization  of a  firm's
current  product  line, damage  to a  firm's  reputation  if  they do not deliver  what  was
promised,  and  potential  litigation  and antitrust  risks  110, 25, 51]. Simply  put,  firms
decide whether or not to preannounce a product if the projected  benefits  gained out-
weigh the signaling costs 110].

The  antitrust  risk  has been  highlighted  by  some recent attempts  at regulation  and
widely publicized litigation. The Software  Publishers Association (SPA) has published
a  set  of  "competition  principles" that  decries  coercion,  vaporware  announcements,
and false claims of competitor incompatibility. These principles are explicitly  framed
to  forestall  government  regulation  of  software  [23]. In  what  has  become  the  most
famous  vaporware  case  in  history,  the  government  filed  a complaint  and  proposed
judgment  after  a four-year  investigation  of Microsoft  [62]. The Federal Trade  Com-
mission  (FTC)  initiated  the  investigation  in  1990 [36]. The  FTC considered  a  wide
range  of practices, including  (1) that  Microsoft  gave  its own developers  of  applica-
tions software  information  about its operating systems software  before providing it to
other applications developers, and (2) that Microsoft  announced that  it was develop-
ing a nonexistent version of operating software to dissuade Original Equipment Manu-
facturers  (OEMs) from  leasing a competitor's operating system. The consent  decree
between Microsoft  and the United States Department of Justice was initially  rejected,
in part, because Microsoft's  "vaporware" announcements had the anticompetitive  ef-
fect  of deterring  consumers  from  buying competing  products  [52]. The  government
has  taken  the  position  that  product  preannouncements  do  not  violate  antitrust  laws
unless those preannouncements are knowingly false and contribute to the acquisition,
maintenance, or exercise of market share. Microsoft  argued that such announcements
were  lawful  because the products  were already  in development.  Microsoft's  market
share  may put it in a unique position  under the antitrust laws. Nonetheless,  software
vendors have made similar accusations against their competitors. Because  Microsoft
is  not the  only  company  to announce  software  long  before  its actual  due  date,  and
because the  announcement  of  a product  before  its release  is not  illegal, prior to the
Microsoft  case, litigation on the issues of vaporware had not been heavily  pursued.

There has been considerable attention in industry and trade press on the reasons for
vaporware  [5, 35, 67], the negative consequences of vaporware  [18. 34,48,53], and
the anticompetitive effects  involved [16, 52, 65]. But few empirical  studies exist that
explore  customers' perceptions  or  reactions  to vaporware  or that examine  the rela-
tionship  of  late  delivery  or poor-quality  software  to a company's  reputation. Addi-
tionally, as a customer invests more capital and human resources into a given  vendor's
solution, they may become dependent upon that vendor. Their need for and interpre-
tation of market signals may then be different  from tbose of the general  marketplace.
This is an area that has not been explored.


SOFTWARE PREANNOUNCEMENTS, CUSTOMERS' PERCEPTIONS. VENDOR REPUTATION  119

Market Sigtialing

Market  signal  research  suggests several  factors  that  determine  a  firm's  strategy  for
preannouncement.  Some are consistent  with the software  market and others are not.
Michael  Spence conceptualized the idea of market signals as a way to pass  informa-
tion to other individuals in the marketplace  [56]. A considerable amount of signaling
research  has been done on the effects  a signal has on a firm's competitor  [10, 11, 13,
24,27,51 ]. The research paradigm behind competitor signaling is game theory. Find-
ing the equilibrium  solution  between firms has been the objective  of several  studies
[2,8,  12,26].

Studies of consumer markets have shown that a preannouncement  will be of value
to tbe extent that competitive advantage can be gained. If a preannouncement is likely
to be  matched,  the  incentive to preannounce  will  be  minimal  [26]. Eliasbberg  and
Robertson  found  that  a  firm  might  preannounce  a  product  based  on  "competitive
behavior"  and  "customer  behavior"  variables  [10].  Explanations  they  found  for
preannouncing  behavior  were  vendor  market  dominance,  company  size  (sales  or
employees), customer switching costs, and customer education requirements. For ex-
ample, preannouncing  appears to hold some risks for large firms due to the potential
antitrust action. Small firms tend not to be susceptible to the risk of injuring competitor's
sales and  therefore  may have greater opportunity  for  preannouncing. This does not
appear to be the case in the software  industry, where tbe large firms consistently  use
preannouncements  and small firms  face  limited  press opportunities. Another  incon-
sistency exists in the area of competitive reaction associated with an industry in which
R&D and technology are specialized by R&D category. According to Eliashberg and
Robertson, pharmaceutical firms tend to specialize by category and that may reduce
the  number  of  competitors  with the potential  to react. A reliance  on  patents  in  tbis
industry also may reduce competitive response. If R&D advantages are limited, com-
petitive response can be rapid. In packaged goods, many firms  avoid  preannouncing
in order to limit the cues about their intentions. The software  industry reflects charac-
teristics of both dimensions. Most software  products require significant  R&D invest-
ment yet face  limited  protection  through copyright  and intellectual  property rights.
Another  form  of  signaling  research  has  focused  on  the  customer  as tbe  primary
receiver of tbe signal. Researchers have studied the effects  of market signals such as
advertising [31, 38], price [47,66], quality  [3], bluffing  [11], switching costs [1, 10],
product preannouncements  [6] and "dry-testing" [52],

An important element that determines  if communication  through  signaling will be
effective  is the signaling firm's reputation. A market signal can be defined  as a signal
put out by the firm  stating its intended actions [27,29]. A company's reputation may
be developed  by fulfilling  or not fulfilling  market  signals  [28]. Reputation  has been
found  to be a very valuable asset  and contributes to company  credibility  [17, 22]. A
good reputation can support sales and be a predictor of a quality product for custom-
ers (15,27]. A good reputation is established by fulfilling  market signals [64]. When a
firm fails to fulfill  its market signals, its reputation and credibility decrease [46]. While
a true market signal  is beneficial  to a firm in establishing a trustworthy  reputation, a


120 

JOHN A. HOXMEIER

mixed market signal is devastating. A true market signal is defined as a market signal
that  has heen accomplished  within  all of the specified  parameters. A mixed  market
signal is a stated intention that the firm does not fulfill.  Herbig et al. demonstrated that
a mixed signal has three to five times the impact of a true signal [29]. It therefore takes
repeated sending of a true signal to reestablish a firm's  reputation.

Hypotheses

THERE  IS  A  PARADOX  IN  THE  SOFTWARE  INDUSTRY.  Many  people  complain  about
vaporware, but at the same time would like to know about new product features and
functions.  In a Computerworld  survey about software  vendors,  80 percent  of those
polled said that preannouncements are useful  for decision-making processes [33]. In
the same survey, 91 percent of those polled preferred to hear about new products. But
68 percent agreed that early information from major vendors like Microsoft  and IBM
can  have a market-freezing  effect  for  small  companies.  Seventy  percent  identified
Microsoft  as the most aggressive preannouncer in the industry. IBM was second with
29 percent,  then  Novell  with  28 percent.  However,  70 percent  said  they  especially
need preannouncement  information  from  Microsoft.  Only 30 percent say they need
information  from  IBM or Novell.

There  is a notable  list of software  products that were announced but either never
delivered or delivered very late [14, 20, 40], When software  preannouncements that
focus on delivery dates are targeted toward the competition rather than the customer—
a form  of "vaporware bluffmg"—customers  can be completely  misled. In business,
relationships are based on some amount of trust. Bluffing  seems to be a violation of
implicit  contract between vendor  and  customer  [U]. The contract  calls for  reason-
ably full  disclosure so a buyer can enter into the transaction  with sufficient  knowl-
edge. Which preaimouncements can the marketplace  trust?

Breaking delivery date promises can hurt the public software market, affect  product
development  cycles, and disrupt  the purchasing plans of corporate  information  sys-
tems (IS) shops [53]. Plus, there is a trickle-down effect of not meeting delivery sched-
ules. IS groups are making promises about delivery when their schedule is detennined
by one or more  vendors, and the vendors themselves may be relying on  someone
else. On-time delivery  is so critical that many times IS shops will take anything a
vendor  can  provide  and  supply  their  own work-arounds  for  incomplete  or  miss-
ing  functionality.

Outside the IS shops, vaporware  is a rampant  threat to many resellers, which  are
forced  to make choices ever more quickly about which technologies to embrace. As
product  cycles  shrink  and  vendors  rush  half-baked  products  to  customers—some-
times little more than proof of concept  until a more complete version can be deliv-
ered—resellers  are  stuck  in  the  middle  between  vendor  promises  and  their  own
development schedules. When products are delayed, it's the reseller's reputation and
business that are on the line. According to Mary Foley of Ziff-Davis,  a  now-defunct
software  development house bet its business on the IBM-Apple-Taligent  object-ori-
ented framework  called OpenDoc, which was superseded  by Java:


SOFTWARE PREANNOUNCEMENTS, CUSTOMERS' PERCEPTIONS, VENDOR REPUTATION  121

"We relied on Apple's and  IBM's ship schedules. They kept lying to us about
their schedules,  and  all the potential  customers they  said they had  lined  up,"
says an official  of the now defunct  developer. [16]

In describing the general situation behind on-time delivery and a particular case in

the software  industry, Ed Foster of InfoWorld states:

After all, if a software vendor promises to deliver something in the summer and
you actually do get it before the end of the year, the vendor would probably feel
that you  got  it earlier than you  had  any right  to expect. From  the  customer's
side of things, though, even a little delay can mean big problems. In the Symantec
case, for  example,  some Visual Cafe  1.0  owners  were losing  business  while
they waited  for  the update. "We all have development  projects  going  on  that
Version  1.0 was holding up," wrote one  1.0 user who had given up on waiting.
"Symantec  knows that we left  ourselves vulnerable by believing that the up-
date was real and would be released  when  available.  Stringing us along with
the promise of the upgrade was what kept us foUowing  Symantec." [18]

Software  companies have  a right to inform  their customers  and prospective  cus-
tomers about their delivery schedules. In other industries, such as the pharmaceutical
industry, such announcements are commonplace. Nonetheless, software vendors should
be aware that there are limits to this well-practiced technique. In the consumer prod-
uct market, mixed market signals have been proven to lower a firm's  reputation if it
repeatedly fails to meet its initial deadlines [27,29]. But research has not focused  on
the software  industry. Presuming the software  industry behaves in a similar  fashion,
this leads to the first hypothesis:

Hj:  Customers rank on-time delivery as the most important characteristic  when
determining  software vendor credibility and reputation.

The software development process remains one of the most uncontrolled and poorly
managed functions  in all of business [9,50]. The software  industry has suffered  from
a trend of delays, unreliable first  releases, and  broken promises  [37, 60, 67]. There
are a number of studies and anecdotal evidence that suggests that a large number of
software  applications fail or are unreliable [57, 63].

Software  projects  have historically  sent  mixed  market  signals.  Software  projects
are completed  on  time  only  16.2 percent  of  the time  [57]. Breaking  delivery  date
promises  can  hurt  the public  software  market,  affect  product  development  cycles,
and  disrupt  the purchasing  plans of corporate  information  systems (IS) shops [53].
According to signaling theory, when a finn  fails to fulfill  its market signals, its repu-
tation and credibility decrease [46].

Software  preannouncing  can be a valuable  tool  for  software  vendors trying  to in-
form customers of new functionality  and improvements. It may be that consumers of
software  products are more concemed  with vendor fulfillment  of promises and  soft-
ware reliability  than they are with on-time delivery  [45]. It may harm  a  company's


122 

JOHN A.  HOXMEIER

reputation and credibility if they are unable to deliver the functionality of the promised
product, even if they deliver on time. This leads to the second hypothesis of this study:

H2: Fulfilled software functionality  promises and reliable software are positively
correlated/associated  with a software vendor's  reputation and credibility.

Customers invest ever increasing financial  and human resources in software  appli-
cations and  the data  they  manage.  Studies have shown  that  IT investment  is tied  to
organizational  strategic and economic  performance  [42]. Yet the nebulous nature of
information  management  makes  it  difficult  to  know  at  the  beginning  of  a  project
whether  a particular  database  tool  is the  ideal  solution  for  a given  problem.  Many
compromises  are  made  during  the  effort,  both  from  a design  and  tools  standpoint.
Once an application  is put into "production" within an organization, a certain  degree
of dependence is created for that software application and the vendor that supplies the
components. Within marketing literature, vendor dependence is tied to switching costs
and customer leaming [10]. Switching costs may be a significant impediment to change
and may favor current competitors by acting as a barrier to new entrants. When data-
base vendors perceive the customer  as being dependent  on them, they may take ad-
vantage of the marketplace  and have less incentive to deliver software  by the  stated
delivery  date. The  customer,  in  many cases,  simply  has  few  alternatives. Also,  the
more  a customer  has  leamed  about  or  invested  in  a vendor's  product  (transaction-
specific investment) and is dependent on a software  vendor, the higher their tolerance
may be for  product delays and  unreliable  releases because their choices are  limited
[ 1 ]. As a customer becomes more dependent on a supplier, the supplier has less incen-
tive to be customer-oriented. Therefore, the supplier is more likely to be unreliable or
late, or it may not fulfill  its promises. This leads to the third hypothesis:

//j.-  Dependence and investment are negatively correlated with reliable software
and fulfilled  promises.

Methodology

THE  STUDY EMPLOYED  A SURVEY TO CAPTURE  DATA from  industry  users of  off-the-
shelf  database  management  software  (DBMS)  software  products.  Studying  a  par-
ticular type of  software  vendor (DBMS  vendors)—rather  than  software  vendors in
general—provided  a more accurate comparison  and narrow  measurement of the de-
pendent  and  independent  variables  discussed  in  the  next  section.  DBMS  vendors
were chosen because most major businesses deal with DBMS products and use data-
bases on a day-to-day  basis. Also, the DBMS market consists of less than ten  major
vendors, providing  for a concentrated  and  homogeneous sample. The  professionals
using  and  purchasing  DBMS  software  on  a daily  basis  were  determined  to  be  IS
managers and database administrators. These professionals  were chosen to complete
the survey and  provide  data  for the study. The  sample  was a mailing  list  of  500 IS
managers  and  database  administrators  randomly  selected  from  the  Computerworld
subscriber database.


SOFTWARE PREANNOUNCEMENTS, CUSTOMERS' PERCEPTIONS. VENDOR REPUTATION  123

Independent Variables

Dependent Variables

On-Time
Delivery

+

Reputation

Figure I.  Dependent and Independent Variables of the Research  Model

Survey Instrument

The survey  instrument  was similar to that used in prior marketing research (see Ap-
pendix A). The package consisted of a cover letter and the survey. The first section of
the survey had four demographic and descriptive questions, for example, the DBMS
product used, size of the company, length of experience with the vendor, and job title.
The second section  had 20 questions rated on a seven-category  Likert scale  ranging
from  "strongly disagree" to "strongly agree." The last three questions dealt with the
number of times the respondent  had encountered  software  that was delayed, unreli-
able, or without the promised features  or  functions.

Construct  Measurement

The  survey  gathered  data  on  seven  composite  measures: four  dependent  and  three
independent. The research  model  is presented in Figure  1.

The individual dependent variables for Section B of the survey instrument are listed

in Table  1  and described  below.

Dependent Variables

Customer's perception  of vendor's  reputation. A  vendor's reputation  in the  market-
place was assessed using three questions. These measured the vendor's fairness  and
honesty in the software industry. The questions used to measure reputation were adapted
from  those used by Anderson and Weitz [1].

Customer's perception of vendor's credibility. The credibiVity of a DBMS  vendor was
measured with three questions. These questions looked at the credibility of promises
made by the vendor, honesty when dealing with problems, and the reliability of their
claims. These questions were adapted from  those used by Ganesan [19].


124 

JOHNA.HOXMEIER

Table  1. Variable Listing Ordered by Dependent Variable

Variable 

Q#t

REP1 
REP2 
REP3 

CRED1 
CRED2 

A.  Customer's perception of the vendor's  reputation
2.  I believe that tbis vendor has a reputation for being fair.
8.  This vendor has a bad reputation in tbe market (R).t
11.  This vendor bas a reputation for being bonest.

B.  Customer's perception of vendor's  credibility
3.  Promises made by this vendor are kept.
4.  If problems such as software delays arise, the vendor is honest about

CRED3 

14.  This vendor does not make false claims.

the problems.

DEP1 

DEP2 
DEP3 

TSI1 

TSI2 

TSI3 

C.  Customer's dependence on the vendor
1.  Tbe relationship with tbis vendor is crucial to the mission of this

organization.

5.  We are dependent on this vendor.
9.  We do not have a good alternative to this vendor.

D.  Customer's transaction-specific  investments
16.  We have made significant investments in training and software

dedicated to our relationship with this vendor.

18.  We have invested substantially  in personnel dedicated to using this

vendor's  product.

19.  If we switched to a competing vendor, we would lose a lot of the

investment  in our current vendor's software.

^ Q# is the survey question number.
* (R) indicates  reverse-worded.

Customer's dependence on the DBMS vendor. The survey respondents were asked to
answer  to  three  questions  focusing  on  the  extent  to  which  the  DBMS  vendor  was
important  to them. The questions  used  to measure  the customer's  dependence  were
adapted from  Ganesan [19].

Customer's  transaction-specific  investments  (TSIs).  Three  questions  were  used  to
measure the extent to which the survey  respondents had invested  in the DBMS ven-
dor. This included investments in training, personnel, and software related to the DBMS
vendor. The  questions  used  to measure  these  investments  were  adapted  from  those
used by Anderson and Weitz [1].

The individual  independent  variables for Section  B of the instrument  are listed in

Table 2 and described  below.

Independent Variables

Credibility of software delivery dates. Three questions were used to measure the cred-
ibility  of  a vendor in delivering software  on time. They also measured  the extent  to
which  late product deliveries  were a problem  with the DBMS vendor.


SOFTWARE PREANNOUNCEMENTS. CUSTOMERS'PERCEPTIONS. VENDOR REPUTATION  125

Table 2. Variable Listing Ordered by Independent Variable 

J ^  " ^ A

Variable

0NTIME1 
0NTIME2 

E.  Credibility of software delivery  dates
7.  This vendor can be trusted to deliver products on time.
12.  When our vendor announces a release date for a new software

product, they release it within one month of the announced date.

0NTIME1 

17.  Late product deliveries are a problem with the vendor (R).*

REL1 
REi_2 

REL3 

F.  Reiiabiiity of software delivered by the vendor
6.  This vendor delivers error-free software.
13.  From past experience, we expect the software from our vendor to

arrive without errors.

15.  When we use this database vendor's software, we do not need to

worry about encountering errors in the program.

FULFiLLI 

G.  Software features and functionality  promised by the vendor
10.  If this vendor promises a certain function or feature on a software

FULFILL2 

20.  This vendor fulfills promises related to software features and

package, it will be there when the software is shipped.

functionality.

^ Q#  is the  survey  question  number.
* (R)  indicates  reverse-worded.

Reliability of software delivered by the vendor.  The extent to which a DBMS vendor
provided customers with error-free  software  was measured using three questions.

Software features  and functionality  promised  by the DBMS  vendor. Two  questions
were used to measure how credible a vendor was when they had promised a  specific
feature  or function  on a piece of  software.

Validation of the Survey  Instrument

Initially,  the  first  draft  of  the  survey  was  pretested  by  20  IS  managers  and  DBMS
administrators  in various businesses. Multiple  survey questions  were  used  for  each
variable  and  several  of  the  questions  were  reverse-coded.  Several  questions  were
modified  based on the pilot and after  running factor  analysis. Cronbach's alpha was
used to test for reliability.

Results

Demographics

A TOTAL OF 95 USABLE QUESTIONNAIRES WERE RECEIVED from  the 500 sent, provid-
ing  a  response  rate  of  19 percent.  A  list  use  agreement  with  Computerworld  pre-
vented  a second  mailing  to the same group. Phone calls to nonrespondents  yielded


126 

JOHN  A.  HOXMEIER

Table 3. Primary Dbms Vendor Chosen by  Respondents

DBMS Vendor 

n 

n/N (%) 

Department 

Size^ 

Company

Size^

Oracle
Microsoft
IBM
Informix
Sybase
Borland
Lotus
Computer Associates
Other
Total N
^ The departmetit and company size figures are averages for the companies using that  vendor.

10,500
2,200
7,200
25,200
1,200
3,600
220
7,500
1,100

11.5
9.4
26.3
4.2
9.4
7.3
1.0
7.3
23.1

11
9
25
4
8
7
1
7
22
95

35
4
62
10
35
19
15
48
32

little to account  for  notiresponse  bias. Reasons for  not responding  included  "didn't
see the survey," "don't have time." and "can't  locate it."

The first question  on  the  survey  instrutnent  requested  the  respondent  to  indicate
their primaiy  DBMS  vendor. These results are shown  in Table 3. Not  including the
"other" category for vendor response, Oracle, IBM, Sybase, and Microsoft  accounted
for  over  50  percent  of  the  responses. This  generally  reflects  market  share data  for
relational  database  management system vendors. The survey also captured  informa-
tion  regarding  department  and  company  size. For both  variables,  there was a  wide
range. The department  size ranged  from  I to 350, with  a mean of 37, and  the com-
pany size ranged from  1  to 100,000, with a mean of 5600. The department and com-
pany size means by vendor are also shown in Table 3. The smaller organizations were
included in the study because it was difficult  to tell whether they represented consult-
ants or small subcontractors. Several reported Oracle as their primary product, which
would be unusual  for a small IT shop.

The second question on the survey requested the respondent to indicate how many
years of experience  they had with  their primary  DBMS  vendor. Most of the  profes-
sionals surveyed  had either heen working with the software  product  for a very  short
period of time (1 to 2 years), or a very long period of time (greater than  10 years).

Survey Findings

The means, standard deviations, and Cronbach's alpha for the measures are presented
in Tables 4 and 5. All of the multiple-item constructs, except dependence, compared
favorably  with the 0.70 or higher desired value for alpha in exploratory research [49].
Generally,  the  mean responses of  the  variables fall  between  the either agree or dis-
agree and slightly agree points on the scale, with standard deviations that imply that
there were few  strong responses. This could indicate that the vendors are  minimally
meeting the needs of  the customers  in these areas. The fact  that there are not strong


SOFTWARE PREANNOUNCEMENTS. CUSTOMERS' PERCEPTIONS, VENIX>R REPUTATION  127

Table 4. Mean, Standard Deviation, and Cronbach's Alpha for Dependent Variables

Construct 

Reputation
Credibility
Customer dependence
Investment

Mean 

5.01
4.81
4.95
5.18

SD 

1.21
1.16
1.33
1.33

Cronbach's Alpha

0.86
0.87
0.71
0.83

Table 5. Mean, Standard

Deviation, and Cronbach

's Alpha for Independent Variables

Construct

Delivery date  credibility
Reliability of  software
Vendor  promises

Mean

4.51
4.31
4.83

SD

1.21
1.45
1.15

Cronbach's Alpha

0.78
0.89
0.82

feelings one way or the other might indicate the basic attitude of "we know we need
this vendor but we are not particularly thrilled about it."

Data Analysis for Reputation and Credibility

The correlation  matrix shown in Table 6 revealed that there were strong relationships
between  the  dependent  variables  REPl,  REP2.  REP3,  and  CRED3  and  all  of  the
independent  variables.

Canonical correlation analysis was performed as tbe second step in the data analysis.
Canonical  correlation  analysis provides an exploratory procedure for studying corre-
lations  between  two sets of  random  variables. Canonical  correlation  analysis  deter-
mines pairs of linear combinations of variables from each set that are representative of
the sets. It also determines the correlations between linear combinations within a pair
[58]. The canonical correlation procedure first finds a linear composite of the multiple
(p) dependent  variables and a linear composite of the multiple  independent  (q) vari-
ables. Next a canonical function  is obtained by correlating the dependent linear com-
posite  with  the  independent  linear composite. When a minimum  of  (p, q)  canonical
functions  has  been  obtained,  the  process  stops. At  this  point,  all  of  the  correlation
between the sets of the dependent and independent variables has been acbieved [41].
SAS was used to perform  the canonical analysis. Table 7 presents tbe results of the

canonical correlation  analysis for reputation and credibility.

Six canonical  functions  were produced by SAS that capture all the correlation  be-
tween the sets of dependent and independent variables. However, only one canonical
function  was used for the study.

The F statistics  in Table 7 sbow that two of the six canonical functions  exceed the
critical  value at the 0.05  level of significance.  However, Stewart and Love state that
use of a single criterion  for  deciding  whether or not a canonical  function  should  be
interpreted  is too confining  [59]. They suggest using redundancy  analysis as well as


m

CD in r^ CD r^ t^
d d Q c^ d d

E

l

L
L
I
F

.

1—1e

l
b
a
i
r
a
V
t
n
e
T3
C

K.

Q;

UJ

C

e
h
t

d
n
a
 
y
t
i
l
i
b
i

d
e
r
C
•a
Srt
co
«
3
a.V
OS
If

i
r
t
a
l

c
O

t
a
l

fcou

\6
u
l
b
a
T

:

E
M

I

zo

UJ

z
o

o

O  Ol ^f O) CD
o  CO en cj CO
in Tt ED to CD
o o o o o

cj CO CO 1^ CO en
<D CO LO O  CO OO
in CO CO cq CO CD
o  d) ci d  d  ci)

^  in o  •^ lo CO
CD in  Tj- CO o  o
Ln  (D CO CD CO CO
(5 <D d Q  d (5

r^ CM CO o  CO
in N  1- 1-  o
in in CD CD <D

d d d

CO  CO -d-
CO  CD  Tf
C«J  •>!; in
d d d

O) in o)
(O ^  r-
iq  •<);  in

o  cvj  Tj-
cj» cj CO
; 
Tf CD in
d d d d d

Ol  Ol O  O  CO  O
Ti- in rD f^ o  in
in in CD CO r-.  CO
d d d d d d

CO CO
Q. 0. Q.
UJ LU LU
cc tr cc

CJ

oLU
CC
o

CO
Q
LU
QC
O

Q
UJ
cc
o

o
d
V
Ci.
*


SOFTWARE PREANNOUNCEMENTS, CUSTOMERS'  PERCEPTIONS, VENDOR REPUTATION 

129

Table 7. Canonical  Correlalion Analysis for Reputation  and Credibility

Test of Ho

: The canonical
all that

correlations in the current row and
follow  are zero

Canonical
Function

Canonical
Correlation

1
2
3
4
5
6

0.916
0.477
0.438
0.284
0.218
0.129

Approx  F

5.213
1.524
1.281
0.834
0.682
0.469

Pr>F

0.0001
0.0328
0.1745
0.6382
0.7063
0.7046

the level of significance to determine which canonical functions should be interpreted
in the analysis. Only canonical  functions  that contribute significantly  to redundancy
with  the dependent  variable set should  be used, that  is. How  much variability  of the
dependent set can be explained  by the independent set? The  first  canonical  function
explains 56.6 percent of the total redundancy. Since the first canonical function  con-
tributed the most to the total redundancy, no other canonical functions  were used.

Test of Hypothesis H^

By looking at the rank order of importance  in Table 8, interesting results emerge.

A software  company's  ability  to  fulfill  promises  related  to  software  features  and
functionality  is ranked higher than any of the other variables. The first hypothesis is
rejected  based  on  this result.  Receiving  reliable  and  error-free  software  is the  next
large group of  variables  affecting  a company's  reputation  and credibility. The  vari-
able that had the least importance  in affecting  reputation  and credibility was the de-
livery of software  on time.

Test of Hypothesis H2

Table 9 presents canonical loadings (linear correlation between  the dependent or in-
dependent set and the set's canonical function)  between individual variables and their
respective canonical  function.

Variables with loadings above 0.710 were interpreted. Catell's Scree Test was used
to determine  the criteria  for significant  canonical  loadings. The  procedure  includes
plotting the variance accounted for by each variable and then looking for an "elbow"
in  the  curve  [21]. In  order  to  plot  the  curve,  the  canonical  loadings  must  first  be
squared. Figures 2 and 3 present scree tests for the individual variables.

In Figure 2, there seems to be an elbow  in the curve at the fifth  principal compo-
nent. For this reason all of the variables, except the fifth  and sixth components (REPl
and REP2), were interpreted  as being  significant.


130 

JOHN  A.  HOXMEIER

Table 8. Rank Order of Importance for Independent Variables

Variables 

Independent  Set 

FULFILI_2 
FULFILL1 
REL3 
0NTIME1 
REL2 
REL1 
0NTIME2 
0
T

N

Canonical  Loadings

Canonical Function 1

0.924
0.842
0.819
0.816
0.772
0.741
0.710

I M E

3

0

.

6

34

\

Table 9. Results of Canonical Analysis for Reputation and Credibility  and the
Independent Variables

Variables 

Dependent Set 

REPl 
REP2 
REP3 
CRED1 
CRED2 
CRED3 

Independent  Set

• 

0NTIME1 
0NTIME2 
0NTIME3 
REL1 
REL2 
REL3 
FULFILL1 
FULFILL2 

Canonical  Loadings

Canonical  Function  I

0.705
0.702
0.909'
0.822'
0.868*
0.894'

0.816*
0.710'
0.634
0.741*
0.772'
0.819*
0.842'
0.924*

*p<0.7I0

In Figure  3, there  seems  to be a slight  elbow  at  the  seventh  component.  For  this
reason all of the variables except the eighth component (0NTIME3) were interpreted
as being  significant.

The rank order of importance for the independent variables contributing to the first
canonical  function  in Table 9 is FULFILL2, FULFILLl,  REL3. ONTIMEl,  REL2,
RELl, ONTIME2, and ONTIME3. The rank order of importance for the dependent
variahles  contributing  to  the  first  canonical  function  is  REP3, CRED3,  CRED2,
CREDl,  REPl,  and  REP2. These rankings  have  a significant  impact  on  the  study,
which will be explored  in the next section.


SOFTWARE PREANNOUNCEMENTS, CUSTOMERS' PERCEPTIONS, VENtX)R REPUTATION  131

= CRB53
= CRED2
= CRH)1

Principal  Components

(ordered from  large to small)

Figure 2. Scree Ttst for Reputation and  Credibility

o  0.8
u.

5  1°"^
8  0.2

•

—

1  =FULF1LL2
2  =  FULFILLl

-

-

-^

5 = REL2
6 =  RB.1

1 

2

3

4

5

6

7 

8  = ONTlhC3

8

Principal Components

(ordered from large to small)

Figure 3. Scree Test for the Independent Variables

The first canonical function  in Table 8 suggests that, except for the variables REP I,
REP2,  and  0NTIME3,  all  of  the  independent  and  dependent  variables  are  signifi-
cantly  and  positively  correlated  with each  other. This, in addition  to the correlation
matrix, supports the second hypothesis, that reputation  and credibility are positively
correlated  with reliable software, on-time software,  and fulfilled  promises.

The final step in the data analysis involved linear regression of the canonical depen-
dent variables versus the canonical independent variables. This was performed  using
the general  linear models procedure  (GLM). Using the composite independent  vari-
able set, one should be able to generate reputation and credibility scores for a certain
company. This score can be used to determine how reputable a company is by looking
at its independent variable ratings. Table 10 presents the results of the GLM. Tahle 10
shows  that  the T  statistic  is equal  to  17.0L  This  is a very  strong  indicator  that  the
parameter is equal to zero. Table 11 presents the rank order of the composite variables
reputation and credibility for the DBMS vendors.

Test of Hypothesis H3

The  correlation  matrix  for  the dependent  variables customer  dependence  and TSIs
and the three independent variables shows that weak and sporadic relationships exist


132 

JOHNA.  HOXMEEER

Table  10. General  Linear Models Procedure for Reputation  and Credibility

Parameter

Estimate

Parameter = 0

T for Ho:

INTERCEPT
CREDREPIND

3.481
0.535

424
17.01

Pr>|T|

0.0001
0.0001

Standard  Error

of Estimate

0.820
0.031

Table  11. DBMS Vendor Scores for Reputation i

ind  Credibility

Company

Reputation

Company

Credibility

Lotus
Other Vendor
IBM
Informix
Borland
Sybase
Oracle
Microsoft
CA

6.33
5.52
5.19
5.58
5.29
5.00
4.94
3.93
3.62

Lotus
Informix
Other Vendor
IBM
Borland
Sybase
Oracle
CA
Microsoft

6.00
5.42
4.82
4.56
4.33
4.11
4.03
3.48
2.89

between the dependent and independent variables. Canonical correlation analysis was
perfonned  as the second step in the analysis and  is shown in Table  12.

The SAS program  produced five canonical  functions. The  F statistics  in Table  12
show  that  one of  the five  canonical  functions  exceeds  the  critical  value  at the  0.05
level of significance. Redundancy analysis was also used to determine which canoni-
cal  functions  to  interpret  [59]. Table  13 presents  the  results  from  the  redundancy
analysis for the dependent  variables customer dependence and TSIs.

The canonical  redundancy  analysis shows that the first canonical  variable is not a
good  overall  predictor  of  the  opposite  set  of  variables. The  proportion  of  variance
explained  is only  12.6 percent. Canonical  variables two through five add  practically
nothing. The cumulative  proportion  for all five is only  17.1 percent.

CatelPs Scree Test was used to determine the criteria for significant  loadings. Fig-
ures 4 and 5 present the scree tests for the individual variables. The elbow appears at
principal component number four. Therefore, only principal components one through
three were inteqireted. Variable loadings for the dependent variables above 0.50 were
considered  to be  significant.

In Figure 5, the elbow  appears at the second  component. Therefore, only  the first

two components were considered  to be  significant.

The  first  canonical  function  suggests  that  0NTIME2  is  positively  and  signifi-
cantly  correlated  with  TSI2,  DEP2, and  TSII.  It  also suggests  that  0NTIME3  is
negatively correlated with TSI2, DEP2, and TSI1. While the hypothesis was that the
independent  variables  were negatively correlated  with the dependent  variables, the
positive correlation  with 0NTIME2 cannot be explained. This does not support the
hypothesis  that a customer's dependence  and  investment  are negatively  correlated
with the three independent variables. Also, looking at the redundancy atialysis (Table


SOFTWARE PREANNOUNCEMENTS. CUSTOMERS' PERCEPTIONS. VENDOR REPUTATION  133

Table  12. Canonical Correlation Analysis for Customer Dependence and
Investment

Test of  HQ: The canonical correlations in the current row and

all that follow  are zero

Canonical
Function

Canonical
Correlation

Approximate F

0.563
0.346
0.255
0,201
0.187

1.442
0.832
0.685
0.661
0.774

P r >F

0,0454
0.7128
0.8242
0.7589
0.5450

Table  13. Canonical Redundancy Analysis for Customer Dependence and
Investment

Canonical
Function

Canonical

0.318
0.028
0.005
0.004
0.006

Cumulative
Proportion

0.126
0.028
0.005
0.004
0,006

Proportion

0.126
0.155
0.161
0.165
0.171

Principal Components

(ordered from  large to small)

Figure 4. Scree Test for Customer Dependence and Inveslnienl

13), the canonical  variable  was  not a good  overall  predictor  of  the opposite  set of
variables.

Summary

Discussion

THE  RESULTS OF THE STUDY REVEAL a significant and positive relationship between a
company's  reputation/credibility  and  reliable  software,  on-time  software,  and  ful-


134 

JOHN A.  HOXMEIER

0.25

1 =OMT1ME
2 = OhfnME3
3 = FULRLL2

6 = FULRLL1

8 = RB.1

Principal Components

(ordered from  large to small)

Figure 5. Scree Test for the Independent Variables

filled  promises. While this is consistetit  with the predictions based on reputation re-
search, it appears that the software  industry  is more tolerant of mixed market  signals
than  markets  studied  in  signaling  research. A software  company's  ability  to  fulfill
promises related to software  features  and functionality  appears to be the highest pri-
orily  of  the  sample  group. The  variable  that  had  the  least  importance  iti  affecting
reputation  and credibility  was the delivery of software  on time. It was hypothesized
that customers want software  when it is promised. This study  has revealed that cus-
tomers are more concerned  with receiving  software  that functions  properly  and  has
all  the  promised  features,  rather  than  getting  it on  the  promised  delivery  date.  But
they seem to be relatively  tolerant of mixed  market signals in general.

The correlation  matrix revealed  that all three of the reputation  variables correlated
with all of  the  independent  variables, while only  one credibility  variable  did. How-
ever, the prediction  level for credibility  was increased when the combined  effects  of
reputation and credibility were considered in the canonical correlation  analysis. This
might be explained by the fact that credibility is the believahility of the current inten-
tion, while reputation is based upon the sum of the past actions of the company [29].
The results seem to suggest that if a software  company focuses on delivering quality
software,  its reputation and credibility will increase.

The  results  of  the  study  did  not  reveal  any  significant  relationship  between  a
customer's  dependence  on a software  company and the quality  of software  they de-
liver. It might be expected that the more dependent a customer  is on a software  ven-
dor, the more they will tolerate late or shoddy software. This was not found to be true.
There seemed to be no correlation between the two variable sets.

Limitations

This study focused  only on software  preannouncements, promises made by  software
vendors,  and  the  reliability  of  delivered  software.  No other  product  characteristics
were  studied. Only  the reactions  of  IS  managers  and  database  administrators  were
studied. The  IS  managers  or  DBMS  administrators  may  have  had  a bias  toward  a
specific  company or product.


SOFTWARE PREANNOUNCEMENTS. CUSTOMERS' PERCEPTIONS. VENDOR REPUTATION  135

The  study  focused  on  the customer  perspective  of  reputation, product  reliability,
and  preannouncements  from  outside  vendors. It did not consider  other channels  or
internal  signaling. Other consumers  in the software  market—such  as users of  inter-
nally developed applications, small businesses, computer programmers, and consult-
ants—might  have  different  opinions  or  attitudes.  Also,  reputation  is  an  imperfect
attribute, since there is a time lag effect  [54]. Attempts to ascertain the nature of this
bias were  inconclusive.

The study  used a survey  instrument  that has the potential  for  inaccuracy  normally
associated  with  this  type  of  instrument.  Nonresponse  bias  must  also  be taken  into
account. Professionals who did not respond to the survey might have a certain bias for
not doing so.

The study did not focus  on individual companies or products, but rather on a gen-
eral consensus of the DBMS software  industry. It may be difficult  to generalize the IS
managers  and  DBMS  administrators  surveyed  to the entire population.  Some  work
for large companies and in large IS departments, whereas others work in small com-
panies with small IS departments. Furthermore, the DBMS software  segment  might
be significantly  different  from  any other software  products in the computer  software
industry. Customer size could be an important  variable to study  in the  future.

Conclusions

It may be difficult  to directly apply signaling theory to the software  industry because
technical preannouncements are necessary forms of communication  in the industry.
In the process of development, software  is gradually exposed  to a broader user base
as  it  matures.  It  is  impossible  to  avoid  creating  some  form  of  vaporware.  Media
demand  for  product  scoops, competition  for  investment  capital,  and  customer  de-
mands  for  advance  notice  of  new  features  put  great  pressure  on  developers  to
preannounce. This  study  revealed  that,  contrary  to  other  industries,  vendors  may
preannounce  optimistic  release  dates  without  fear  of  alienating  the customer.  One
possible  explanation  for  this inconsistency  is that  in the DBMS toots  marketplace,
the vendor and the customer have similar characteristics. DBMS sales scenarios are
usually  highly  technical. The  customer  is looking  for  an  application  environment
and data repository  they can use to deploy organizational  information  systems. The
customer  may  be  more tolerant  of  mixed  signals  from  the  vendor  because  they  in
turn are probably sending mixed signals to the ultimate infonnation  consumer. There
has been an escalating trend of software  failures and delays that have led to substan-
tial cost overruns. The Standish Group research shows that a staggering 31.1 percent
of IT projects  will be canceled  before  they ever get completed. Further results indi-
cate  that  52.7  percent of  projects  will  cost  189 percent  of  their original  estimates
157]. While  unforeseen  events  and  unfulfilled  promises  will  unfortunately  always
plague the software development process, communication to the marketplace should
be  improved.

This  study  has  shown  that  there  is  a  positive  relationship  between  a  company's
preannouncement policies and practices, the quality of their products, and their public


136 

JOHNA.HOXMEIER

image.  The  results  also  reveal  a  significant  and  positive  relationship  between  a
company's reputation and credibility and whether they deliver on what was promised.
This and other research on  market signaling provides evidence that customers  make
inferences  about the motives underlying  vendors' market actions. Signaling  research
reveals that  signals sent and received  by competitors  are interpreted  and  acted on—
though  not  always  to  the  detriment  of  the  vendor's  reputation  and  the  competitive
process.

Courts and the FTC are still  in the early  stages of defming  the parameters of the
relationship between software  market signaling and antitrust law. Should the federal
government  regulate  preannouncements?  Seventy-seven  percent  in the  Computer-
world  survey  said no  [33]. Some said  vaporware announcements  will  hurt  vendors
in the  long run, so they will  police  themselves. In  1990, the now-defunct  Software
Business Practices Council  recommended  that the time between announcement  and
availability  should  be no more than nine months  143, 55]. This standard  has  gener-
ally been  ignored.

So  what  constitutes  a signal  in  the  software  marketplace?  Generally,  software
preannouncement  signals  are safely  sent  if  they  focus  on  improved  functionality
or  new  features;  provide  truthful  information  to competitors,  suppliers,  and  cus-
tomers; or enhance competition. To minimize the chance that a vendor's  signaling
behavior  is  perceived  as  questionable  in  an  antitrust  sense,  software  companies
should avoid signaling that implies a sole intent of reducing competition.  Improv-
ing the reliability of the signal should result in improved reputation  and credibility
in  the  marketplace.  Firms  must  decide  if  the  projected  benefits  gained  outweigh
the  signaling  costs.  Because  the  software  industry  appears  to  behave  differently
from  other  industries,  further  research  on  the  vaporware/antitrust  relationship  is
warranted.

There are many additional  avenues to pursue when trying to apply  what is known
about signaling to the software  industry. Additional insight is needed to quantify  how
much  an  exemplary  reputation  and  credibility  in  the  marketplace  actually  affect  a
software  company's  sales. In this  study, Microsoft,  together  with  IBM  and  Oracle,
ranked toward the bottom in reputation, credibility, and quality. As the world's largest
independent  software  company, Microsoft  also has a reputation  as the most aggres-
sive preannouncer  133]. However, from  1994 to  1999, Microsoft,  IBM,  and  Oracle
provided returns to shareholders of  !,000 percent, 442 percent, and 687 percent, re-
spectively,  and  all  have  experienced  significant  sales  growth.  In  November  1999,
following  the ruling by Judge Thomas  Penfield  Jackson  that  Microsoft  has  unfairly
stifled  competition,  a Gallup poll  revealed  that  66 percent  of  consumers  still  had a
favorable  view of  Microsoft.

Finally,  this  study  was  an  application  of  signaling  theory  used  in  marketing  re-
search toward the impact of software  preannouncements. Because software  is unlike
most  other  consumer  products,  further  investigation  is  required  to  understand  the
relationship between vendor and customer and between  vendor and competitor, and
to  identify  the  characteristics  of  positive  signals  and  the  predictors  of  a  software
company's  reputation.


SOFTWARE PREANNOUNCEMENTS. CUSTOMERS' PERCEPTIONS, VENDOR REPUTATION  137

Acknowledgments:  The author would like to acknowledge the assistance of Franz  Garsombke
of Corporate  Express on this study, thecooperationofCom/ju/erworW  for supplying the mail-
ing list, and the advice and contributions of the editor and anonymous  reviewers.

REFERENCES

1. Anderson,  E., and Weitz, B.A. The  use of pledges to build  and  sustain commitment  in

distribution  channels. Journal  of Marketing  Research,  29.  1  (February  1992),  18-34.

2. Banks, J.S., and Sobel, J. Equilibrium selection in signaling games. Econometrica,  55, 3

(May  1987), 647-661.

3. Boulding, W., and Kirmani, A. A consumer-side  experimental  examination  of signaling
theory:  do  consumers  perceive  warranties  as  signals  of  quality?  Journal  of  Consumer  Re-
search.  20.  1 (June  1993), 111-123.

4.  Brandel, W. Late, unstable  wares  plague  IS projects.  Computerworld,  28,  21  (May  21

1994),  1, 14.

5. Brandel, W. Product propaganda battle rages on. Computerworld,  28. 22 (May 30,1994),

41.

6.  Brockhoff,  K.K.,  and  Rao,  V. Toward  a  demand  forecasting  model  for  preannounced
new technological  products. Journal  of Engineering  and Technology Management.  10, 3 (Sep-
tember  1993), 211-228.

7.  Casselman,  G.  Vaporware:  vile  or  valid?  Computing  Canada,  17,  26  (December  19,

1991)  1,5.

8. Cho,  1., and  Kreps,  D.M.  Signaling  games and  stable  equilibria.  Quarterly  Journal  of

Economics.  102. 2 (May  1987),  179-221.

9.  Dawson,  S.P.  Continuos  improvements  in  action:  applying  quality  principles  to  soft-

ware. Information  Systems  Management,  II,  1  (Winter  1994), 31-39.

10. Eiiashberg, J., and Robertson, T.S. New product preannouncing behavior: a market  sig-

naling study. Journal  of Marketing  Research,  25,  3 (August  1988), 282-292.

11. Eiiashberg, J.; Robertson, T.S.; and Rymon, T. Market signaling and competitive  bluff-

ing. Working paper. The Wharton  School, University  of Pennsylvania  (1992).

12. Engers, M. Signaling with many  signals. Econometrica,  55, 3 (May  1987), 663-674.
13.  Engers,  M.,  and  Fernandez,  L.  Market  equilibrium  with  hidden  knowledge  and  self-

selection. Econometrica.  55, 2 (March  1987), 425-439.

14. Famous Vaporware Products. Byte Magazine,  September 1995; www.byte.coni/art/9509/

sec 7/art26.htm,  accessed  11/99.

15. Fitzgerald, T.J. Understanding the differences  and similarities between services and prod-
ucts to exploit your competitive advantage. Journal of Services Marketing,  2,  I (Winter  1988),
25-30.

16. Foley, M. Vapor: Where? ZDNet, May 20,1998.  http://www.zdnet.com/sr/columns/foley/

980519.html, accessed  11/11/99.

17.  Fombnin,  C,  and  Shanley,  M.  What's  in  a  name?  Reputation  building  and  corporate

strategy. Academy  of Management  Journal,  33, 2 (June  1990), 233-258.

18.  Foster,  E.  Vaporware  is  more  than just  annoying—it  can  be  downright  expensive.
infoWorld.  December  1,  1997.  http://www.infoworld.com/cgi-bin/dispIayNew.pl7/foster/
97120Ief htm, accessed  11/99.

19. Ganesan, S. Detemiinants of long-term  orientation  in buyer seller relationships. Jburna/

of Marketing.  58. 2 (April  1994),  1-19.

20. Gillin, P  Vaporstriking.  Computerworld,  28. 6 (February  7,  1994), 34.
21.  Green, R Analyzing  Multivariate  Data.  Hinsdale, IL: Dryden  Press, 1978.
22.  Hall,  R. The strategic  analysis of  intangible  resources. Strategic  Management  Journal,

13. 2 (February  1992),  135-145.

23.  Hayes, F. Pow! Right  in the kisser.  Computerworld,  February  9, 1998.
24. Heil, O.P., and  Robertson, T.S. Toward  a theory  of competitive market  signaling: a re-

semc\i  agenda. Strategic Management  Journal,  12, 6 (September  1991), 403-419.

25. Heil, O.P., and Langvardt, A. W. The interface between competitive market signaling and

^.  Journal  of Marketing.  58. 3 (July  1994), 81-96.


138 

JOHN A. HOXMEIER

26. Heil, O.P., and Walters, R.G. Explaining competitive reactions to new products: an empiri-
cal signaling study. yoi//7ia/o//*TO(/ucr/nnovafton  Managemem,  10, 1  (January  1993), 53-66.

27. Herbig, P. Market signalling: a review. Management  Decision.  34.  1 (1996), 35-45.
28. Herbig, P., and Milewicz, J. The relationship of reputation and credibility to brand suc-

cess. Journal  of Consumer Marketing,  10, 3 (Summer  1993),  18-24.

29. Herbig, P.; Milewicz, J.; and Golden, J. A model of reputation building and destruction.

Journal  of Business Research, 31,  1 (September  1994), 23-31.

30. Hosage, D.A, Realware v. vaporware.  Telecommunications,  19. 2 (Febmary  1985), 6 5-

66.

31.  Ippolito, P.M. Bonding and nonbonding signals of product quality. Journal  of  Business,

63.  1 (January  1990), 41-60.

32. Jenkins, A. Long overdue: the reasons behind vaporware. Computerworld, 22. 40a (Oc-

tober 5,  1988),  11-13.

33.  Johnston,  S.J.  Vaporware  tactics  elicit  mixed  views.  Computerworld,  29.  18 (May  1,

1995),  1, 147.

34. Johnston,  S.J.,  and  Betts, M.  Industry  debates  U.S. vaporware  probe.  Computerworld,

2P, 7 (February  13, 1995), 2.

35. Kay, S. Poor communication equals vaporware. Com/jurerworW, 2(5, 2 (January 13,1992),

81-82.

36. Keefe, P. Microsoft  feels beat of FTC investigation. Computerworld,  25,  11 (March  18,

1991),  1, 101.

37. Keen, P. Instead of tbe perfect product, bow about the perfect  supplier?  Computerworld,

September  14, 1998.

38. Kiblstrom, R.E., and Riordan, M.H. Advertising as signal. Journal of Political Economy,

92.31  (June  1984), 427-450.

39. Kohli, C.S. Signaling new product  introductions: a framework  to explain  the timing of

preannouncements. Ph.D. dissertation,  Indiana University,  1992.

40. Lawton,G.Software  sbip dates under scrutiny.^o/ftvfl/ie Magazine, 15, 1  (January  1995),

26.

41.  Levine,  M.S.  Canonical Analysis  and  Factor  Comparison.  Beverly  Hills,  CA:  Sage,

1967.

42. Mahmood, M., and Mann, G. Measuring the organizational  impact of infomiation  tech-
nology investment: An exploratory  study. Journal  of Management Information Systems,  10. 1
(Summer  1993), 97-122.

43. Margolis, N. Software  clan to patrol bype. Computerworld.  24, 42 (October  15,1990),

1,8.

44.  McConnell,  S.  Code  Complete:  A  Practical  Handbook  of  Software  Construction.

Redmond, WA: Microsoft  Press, 1993.

45.  Meachim,  N. Users to vendors: quality,  quality, quality. Datamation,  40,  12 (June  15,

1994), 38-45.

46. Milewicz, J., and  Herbig,  P. Evaluating the brand extension  decision using a model  of

re^\x\zX\onhui\6\n%. Journal  of Brand and Product Management,  3,  1  (1994),  1-12.

47. Milgrom, P., and Roberts, J. Price and advertising signals of product quality. Journal  of

Political Economy, 94, 4 (August  1986), 796-821.

48.  Nash,  K.S. Vendors  fudge  on  product  ship dates.  Computerworld.  29.  6  (February  6,

1995), 81.

49. Nunnally, J.C  Psychometric  Theory. New York: McGraw-Hill,  1967.
50.  Pressman, R. Software  Engineering: A  Practitioner's  Approach.  New Yoik:  McGraw-

Hill,  1997, p. 7.

51.  Robertson, T;  Eiiashberg, J.;  and  Rymon, T. New  product  announcement  signals  and

incumbent reactions. Journal  of Marketing,  59, 3 (July  1995), 1—15.

52. Rose, L. Vaporware rules: the limits on dry-testing. Marketing Computers (March  1995).

www.webcom.com/-lewrose/article/vapor.html,  accessed  11/11/99.

53. Scannell, E., and Johnston, S. Microsoft  tardiness can derail developers. Computerworld.

28,2\  (May 21, 1994),  1, 14.

54.  Sbapiro,  C.  Premiums  for  bigh  quality  products  as  returns  to  reputations.  Quarterly

Journal  of Economics.  98, 4 (November  1983), 659-679.


SOFTWARE PREANNOtJNCEMENTS, CUSTOMERS' PERCEPTIONS, VENDOR REPUTATION  139

55. Sherer, P.M. Vendor group vows to improve ethical standards of the industry. PC Week.

7. 41 (October  15, 1990),  157, 164.

56. Spence, M. A. Market  Signaling. Cambridge, MA: Harvard University  Press, 1974.
57.  Standish  Group.  The  Chaos  Report  [Online],  1997.  http://www.standishgroup.com/

chaos.html, accessed  ll/U/99.

58. Stevens, S. Applied Multivariate Statistics for  the Social Sciences. Hillsdale, NJ:Lawrenee

Erlbaum Associates Publishers,  1986.

59. Stewart, D., and Love, W. A general canonical con-elation index. Psychological Bulletin,

70.3(1968),  160-163.

60. Strassmann, P. The road to failure  is paved with glib buzzwords. Computerworld.  Octo-

ber 5, 1998.

61. Strong, D.; Lee, Y.; and Wang, R. Data quality in context. Communications o/the  ACM.

40.  5(1997),  103-110.

62.  United  States v. Microsoft  Corporation,  56 F.3d,  1448  1451-52, Civil Action  No. 94-

1564, (D.C. Cir.  1995), (Stanley Sporkin) 2/14/95.

63. Wand, Y., and Wang, R. Anchoring data quality dimensions in ontological  foundations.

Communications of the ACM, 39.  11 (1996), 86-95.

64.  Weigelt,  K.,  and  Camerer,  C.  Reputation  and  corporate  strategy:  A review  of  recent
theory and applications. 5/rar^icA/anageme/i/Jburna/,  9, 5 (September-October  1988), 44S-
456.

65. Weinberg, N.; Brandel,  W.; and  Johnston,  S.J.  Users  willing  to  ride  Microsoft  jugger-

naut. Computerworld.  29. 6 (February  6,  1995),  1, 28-29.

66. Wolinsky, A. Prices as signals of product quality. Review of Economic  Studies. 50.  163

(October  1983), 647-658.

67. Zachary, G.P. We're still waiting.  Wall Street Journal.  12. 102 (June 27,1994), R8.


